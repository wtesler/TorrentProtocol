/* Copyright (c) 2014 Will Tesler */

#include "TorrentNode.h"
#include "TorrentNodeList.h"
#include "Constants.h"
#include <climits>
#include <iostream>
#include <mpi.h>
#include <string>
#include <sstream>

#define DEBUG false

typedef char BYTE;
typedef int FLAG;

#pragma once
class Manager {

private:

    // Contains the file that you want to share.
    BYTE * data;

    // Prioritized Linked List of segments of data.
    TorrentNodeList * list;

    // Number of processors participating in the network
    int networkSize;

    // Stores messages for debugging
    vector<string> messageBuffer;

    // Stores an array of requests associated with each worker.
    MPI_Request * terminationRequests;

public:

    // Constructor
    Manager(int size) : networkSize(size) {

        //a bunch of randomly generated byte data for testing.
        data = new char[DATA_SIZE_IN_BYTES];

        // initialize the data to random values.
        for (unsigned int i = 0; i < DATA_SIZE_IN_BYTES; i++) {
            // rand actually is psuedo-random, but it gets the job done.
            data[i] = rand() % CHAR_MAX;
        }

        // Structure the data into prioritizable chunks
        list = new TorrentNodeList(data, DATA_SIZE_IN_BYTES, CHUNK_SIZE_IN_BYTES);

        // One termination request per worker.
        terminationRequests = new MPI_Request[networkSize-1];
    }

    // Destructor
    ~Manager() {
        delete[] data;
        delete list;
        delete[] terminationRequests;
    }

    // Send a chunk of data to each computer inside addresses.
    void sendChunk(BYTE * data, int length, int chunkPosition, vector<int> addresses) {
        for (unsigned int i = 0; i < addresses.size(); i++) {

            if (DEBUG) {
                stringstream ss;
                ss << "Manager sending chunk " << chunkPosition << " to Worker " << addresses[i];
                messageBuffer.push_back(ss.str());
            }

            MPI_Send(data, length, MPI_CHAR, addresses[i], TAG_DATA_REQUEST, MPI_COMM_WORLD);
        }
    }

    // Sends a work order to a computer.
    // Tells that computer to send data to another computer.
    void sendWorkOrder(int dest, int chunkPosition, vector<int> addresses) {

        if (DEBUG) {
            stringstream ss;
            ss << "Sending Work Order to " << dest;
            messageBuffer.push_back(ss.str());
        }

        // We store the position of the chunk in the last index of the vector.
        // Every other index contains rank addresses.
        addresses.push_back(chunkPosition);

        MPI_Send(&addresses[0], addresses.size(), MPI_INT, dest, TAG_WORK_ORDER, MPI_COMM_WORLD);
    }

    // This kicks off the Manager and begins the entire uploading/downloading network (swarm)
    void start() {

        // Requests and Statuses used by the Manager.
        MPI_Request dataRequest, terminationRequest;
        MPI_Status dataStatus, terminationStatus;

        // Asynchronously receive data request.
        int chunkPosition;
        FLAG dataFlag = -1;

        int dummy;

        // Keeps track of how many workers have finished
        int numTerminations = 1;
        for (int i = 0; i < networkSize - 1; i++) {
            MPI_Irecv(&dummy, 1, MPI_INT, i+1, TAG_TERMINATION_NOTICE, MPI_COMM_WORLD, &terminationRequests[i]);
        }

        // Keeps track of how many times the main loop iterates (mod INT_MAX).
        // Useful for pacing the Manager.
        int i = 0;

        // MAIN LOOP. Will only exit when there are no more workers in the swarm.
        while(numTerminations < networkSize){

            if(dataFlag != 0){
                MPI_Irecv(&chunkPosition, 1, MPI_INT, MPI_ANY_SOURCE, TAG_DATA_REQUEST, MPI_COMM_WORLD, &dataRequest);
                dataFlag = 0;
            }
            // Test to see if a data request has been received.
            MPI_Test(&dataRequest, &dataFlag, &dataStatus);
            // If request has been received.
            if (dataFlag != 0) {
                if (dataStatus.MPI_SOURCE != -1) {
                    //process the new request.
                    processDataRequest(&dataStatus, chunkPosition);
                }
                dataFlag = -1;
            }

            // Test to see if any termination notices came in.
            for (int j = 0; j < networkSize-1; j++) {
                FLAG terminationFlag = -1;
                MPI_Test(&terminationRequests[j], &terminationFlag, &terminationStatus);
                if (terminationFlag != 0) {
                    if (terminationStatus.MPI_SOURCE != -1) {
                        ++numTerminations;
                    }
                } 
            }

            // Manager helps out with the data every so often (as defined by MANAGER_SEND_FREQ).
            if (i % networkSize == 0) {
                // This chunk of data currently has the highest priority.
                TorrentNode * chunk = static_cast<TorrentNode*>(list->lead);
                // Synchronously send the data each computer on the waitlist.
                sendChunk(chunk->getData(), chunk->getDataLength(), chunk->getPosition(), chunk->getWaitlist());
                // Reset the priority and waitlist of sent chunk.
                chunk->clearWaitlist();
                list->set(chunk, 0);
            }

            // Prevents oveflow.
            if (i == INT_MAX) { i = 0;}
            i++;
        }

        // Print debug info from the message buffer
        if (DEBUG) {
            stringstream ss;
            ss << "Manager has terminated";
            messageBuffer.push_back(ss.str());

            for (string s : messageBuffer) {
                cout << s << endl;
            }
        }
    }

    // 1. Extracts info from the request.
    // 2. Adjusts list to reflect info.
    // 3. Conditionally sends a work order to the source.
    void processDataRequest(const MPI_Status * status, const int chunkPosition) {

        // The computer that sent us the request.
        int source = status->MPI_SOURCE;

        if (DEBUG) {
            stringstream ss;
            ss << "Worker " << source << " wants chunk " << chunkPosition;
            messageBuffer.push_back(ss.str());
        }

        // This is the chunk that source wants
        TorrentNode * desiredChunk = static_cast<TorrentNode*>(&list->nodeAt(chunkPosition));

        // Adds source to the waitlist if not already on it.
        desiredChunk->add(source);

        // Raise priority of chunk to reflect source's message.
        list -> set(desiredChunk, desiredChunk->getPriority() + 1);

        // See if the worker can help out.
        createWorkRequest(source, chunkPosition, desiredChunk);

    }

    // If the source can help out, send it a work order.
    void createWorkRequest(const int source, const int chunkPosition, TorrentNode * desiredChunk) {

        // Start from the front, and we will make our way to the back.
        TorrentNode * iter = static_cast<TorrentNode*>(list->lead);

        // Loops as long as there is still a potential chunk that source can help out with.
        while (iter != nullptr && iter->getPriority() > 0) {

            if (DEBUG) {
                stringstream ss;
                ss << "Checking to see if Worker " << source << " can help with chunk " << iter->getPosition();
                messageBuffer.push_back(ss.str());
            }

            // If the source is ahead of the prioritized chunk
            if (chunkPosition > iter->getPosition()){

                // Tell the source to do some work.
                sendWorkOrder(source, iter->getPosition(), iter->getWaitlist());

                // Reward the source for helping out.
                list -> set(desiredChunk, desiredChunk->getPriority() + iter->getWaitlist().size());

                // Reset the node's waitlist and priority.
                iter->clearWaitlist();
                list->set(iter, 0);

                break;
            }

            // Try the next chunk
            iter = static_cast<TorrentNode*>(iter->back);
        }

    }

};
